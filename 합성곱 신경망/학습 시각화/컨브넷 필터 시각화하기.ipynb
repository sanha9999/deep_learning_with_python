{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과정\n",
    "* 1.  특정 합성곱 층의 한 필터 값을 최대화하는 손실 함수를 정의한다.\n",
    "> 이 활성화 값을 최대화하기 위해 입력 이미지를 변경하도록 확률적 경사 상승법을 사용한다. 예를 들어 여기에선 ImageNet에 사전 훈련된 VGG16 네트워크에서 block3_conv1 층 필터 0번의 활성화를 손실로 정의한다.\n",
    "> ### 필터 시각화를 위한 손실 텐서 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras import backend as K\n",
    "\n",
    "model = VGG16(weights='imagenet',\n",
    "              include_top=False)\n",
    "\n",
    "layer_name = 'block3_conv1'\n",
    "filter_index = 0\n",
    "\n",
    "layer_output = model.get_layer(layer_name).output\n",
    "loss = K.mean(layer_output[:, :, :, filter_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 경사 상승법을 구현하기 위해 모델의 입력에 대한 손실의 그래디언트가 필요하다. 이를 위해 케라스의 backend 모듈에 있는 gradients 함수를 사용한다.\n",
    "> ### 입력에 대한 손실의 그래디언트 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "grads = K.gradients(loss, model.input)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 경사 상승법 과정을 부드럽게 하기 위해 사용하는 한 가지 기법은 그래디언트 텐서를 L2 노름(텐서에 있는 값을 제곱한 합의 제곱근)로 나누어 정규화하는 것이다.\n",
    "> ### 그래디언트 정규화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5) # 0나눗셈을 방지하기 위해 1e - 5를 더한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 주어진 입력 이미지에 대해 손실 텐서와 그래디언트 텐서를 계산해야 한다. \n",
    "> ```iterate```는 넘파이 텐서(크기가 1인 텐서의 리스트)를 입력으로 받아 손실과 그래디언트 2개의 넘파이 텐서를 반환한다.\n",
    "> ### 입력 값에 대한 넘파이 출력 값 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterate = K.function([model.input], [loss, grads])\n",
    "\n",
    "import numpy as np\n",
    "loss_value, grads_value = iterate([np.zeros((1, 150, 150, 3))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 확률적 경사 상승법을 사용한 손실 최대화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img_data = np.random.random((1, 150, 150, 3)) * 20 + 128. # 잡음이 섞인 회색 이미지로 시작\n",
    "\n",
    "step = 1. # 업데이트할 그래디언트의 크기\n",
    "for i in range(40): # 경사 상승법을 40회 실행\n",
    "    loss_value, grads_value = iterate([input_img_data])\n",
    "    # 손실과 그래디언트 계산\n",
    "    input_img_data += grads_value * step\n",
    "    # 손실을 최대화하는 방향으로 입력이미지를 수정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 결과 이미지 텐서는 (1, 150, 150, 3)크기의 부동 소수 텐서이기 때문에 후처리할 필요가 있다.\n",
    "> ### 텐서를 이미지 형태로 변환하기 위한 유틸리티 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1 # 텐서의 평균이 0, 표준편차가 0.1이 되도록 정규화한다.\n",
    "    \n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1) # [0, 1]로 클리핑한다.\n",
    "    \n",
    "    x *= 255\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x # RGB 배열로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 필터 시각화 이미지를 만드는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def generate_pattern(layer_name, filter_index, size=150):\n",
    "    # 주어진 층과 필터의 활성화를 최대화하기 위한 손실 함수를 정의합니다\n",
    "    layer_output = model.get_layer(layer_name).output\n",
    "    loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "    # 손실에 대한 입력 이미지의 그래디언트를 계산합니다\n",
    "    grads = K.gradients(loss, model.input)[0]\n",
    "\n",
    "    # 그래디언트 정규화\n",
    "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "\n",
    "    # 입력 이미지에 대한 손실과 그래디언트를 반환합니다\n",
    "    iterate = K.function([model.input], [loss, grads])\n",
    "\n",
    "    # 잡음이 섞인 회색 이미지로 시작합니다\n",
    "    input_img_data = np.random.random((1, size, size, 3)) * 20 + 128.\n",
    "\n",
    "    # 경사 상승법을 40 단계 실행합니다\n",
    "    step = 1.\n",
    "    for i in range(40):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "\n",
    "    img = input_img_data[0]\n",
    "    return deprocess_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(generate_pattern('block3_conv1', 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 층에 있는 각 필터에 반응하는 패턴 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_name in ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1']:\n",
    "    size = 64\n",
    "    margin = 5\n",
    "\n",
    "    # 결과를 담을 빈 (검은) 이미지\n",
    "    results = np.zeros((8 * size + 7 * margin, 8 * size + 7 * margin, 3), dtype='uint8')\n",
    "\n",
    "    for i in range(8):  # results 그리드의 행을 반복합니다\n",
    "        for j in range(8):  # results 그리드의 열을 반복합니다\n",
    "            # layer_name에 있는 i + (j * 8)번째 필터에 대한 패턴 생성합니다\n",
    "            filter_img = generate_pattern(layer_name, i + (j * 8), size=size)\n",
    "\n",
    "            # results 그리드의 (i, j) 번째 위치에 저장합니다\n",
    "            horizontal_start = i * size + i * margin\n",
    "            horizontal_end = horizontal_start + size\n",
    "            vertical_start = j * size + j * margin\n",
    "            vertical_end = vertical_start + size\n",
    "            results[horizontal_start: horizontal_end, vertical_start: vertical_end, :] = filter_img\n",
    "\n",
    "    # results 그리드를 그립니다\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(results)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 이런 필터 시각화를 통해 컨브넷 층이 바라보는 방식을 이해할 수 있다. 컨브넷의 각 층은 필터의 조합으로 입력을 표현할 수 있는 일련의 필터를 학습한다. 이는 푸리에 변환을 사용하여 신호를 일련의 코사인 함수로 분해할 수 있는 것과 비슷하다. 이 컨브넷 필터들은 모델의 상위층으로 갈수록 점점 더 복잡해지고 개선된다.\n",
    "* 모델에 있는 첫 번째 층의 필터는 간단한 대각선 방향의 에지와 색깔(또는 색깔이 있는 에지)를 인코딩한다.\n",
    "* block2_conv1의 필터는 에지나 색깔의 조합으로 만들어진 간단한 질감을 인코딩한다.\n",
    "* 더 상위층의 필터는 깃털 , 눈, 나뭇잎 등 자연적인 이미지에서 찾을 수 있는 질감을 닮아 가기 시작한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
