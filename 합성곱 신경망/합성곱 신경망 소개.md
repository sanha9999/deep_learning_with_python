# 합성곱 신경망 소개
------------------------------
> #### 컨브넷이 (image_height, image_width, image_channels) 크기의 입력 텐서를 사용한다는 점이 중요하다(배치차원 미포함). 이 때문에 input_shape에 28, 28, 1을 넣었구만.
-----------------------------
> ### 합성곱 연산
> #### 완전 연결층과 합성곱 층 사이의 근본적인 차이는 무엇일까? 바로 Dense 층은 입력 특성 공간에 있는 전역 패턴을(예를 들어 MNIST 숫자 이미지에서는 모든 픽셀에 걸친 패턴)을 학습하지만 합성곱 층은 지역 패턴을 학습한다는 것에서 차이가 있다.
> #### 이 핵심 특징은 컨브넷에 두가지 재밌는 성질을 제공한다!!
* **학습된 패턴은 평행 이동 불변성을 가진다.**
> 컨브넷이 이미지의 오른쪽 아래 모서리에서 어떤 패턴을 학습했다면 다른 곳 에서도 이 패턴을 인식할 수 있다. 완전 연결 네트워크는 새로운 위치에 나타난 것은 새로운 패턴으로 학습해야 한다. 이런 성질은 컨브넷이 이미지를 효율적으로 처리하게 해준다!!
* **컨브넷은 패턴의 공간적 계층 구조를 학습 할 수 있다**
> 첫 번째 합성곱 층이 에지 같은 작은 지역 패턴을 학습한다. 두 번째 합성곱 층은 첫 번째 특성으로 구성된 더 큰 패턴을 학습한다. 이런 방식을 사용하여 컨브넷은 아주 복잡하고 추상적인 시각적 개념을 효과적으로 학습할 수 있다.
> #### 합성곱 연선은 특성 맵이라고 부르는 3D텐서에 적용된다. 이 텐서는 높이와 넓이, 깊이 축(채널이라고도 부름)으로 구성된다. RGB이미지는 깊이 축의 차원이 3이된다. 합성곱 연산은 입력 특성 맵에서 작은 패치들을 추출하고 이런 모든 패치에 같은 변환을 적용하여 출력 특성 맵을 만든다.
