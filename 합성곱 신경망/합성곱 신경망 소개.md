# 합성곱 신경망 소개
------------------------------
> #### 컨브넷이 (image_height, image_width, image_channels) 크기의 입력 텐서를 사용한다는 점이 중요하다(배치차원 미포함). 이 때문에 input_shape에 28, 28, 1(1은 회색을 의미하는듯..)을 넣었구만.
-----------------------------
> ### 합성곱 연산
> #### 완전 연결층과 합성곱 층 사이의 근본적인 차이는 무엇일까? 바로 Dense 층은 입력 특성 공간에 있는 전역 패턴을(예를 들어 MNIST 숫자 이미지에서는 모든 픽셀에 걸친 패턴)을 학습하지만 합성곱 층은 지역 패턴을 학습한다는 것에서 차이가 있다.
> #### 이 핵심 특징은 컨브넷에 두가지 재밌는 성질을 제공한다!!
* **학습된 패턴은 평행 이동 불변성을 가진다.**
> 컨브넷이 이미지의 오른쪽 아래 모서리에서 어떤 패턴을 학습했다면 다른 곳 에서도 이 패턴을 인식할 수 있다. 완전 연결 네트워크는 새로운 위치에 나타난 것은 새로운 패턴으로 학습해야 한다. 이런 성질은 컨브넷이 이미지를 효율적으로 처리하게 해준다!!
* **컨브넷은 패턴의 공간적 계층 구조를 학습 할 수 있다**
> 첫 번째 합성곱 층이 에지 같은 작은 지역 패턴을 학습한다. 두 번째 합성곱 층은 첫 번째 특성으로 구성된 더 큰 패턴을 학습한다. 이런 방식을 사용하여 컨브넷은 아주 복잡하고 추상적인 시각적 개념을 효과적으로 학습할 수 있다.
> #### 합성곱 연산은 특성 맵이라고 부르는 3D텐서에 적용된다. 이 텐서는 높이와 넓이, 깊이 축(채널이라고도 부름)으로 구성된다. RGB이미지는 깊이 축의 차원이 3이된다. 합성곱 연산은 입력 특성 맵에서 작은 패치들을 추출하고 이런 모든 패치에 같은 변환을 적용하여 출력 특성 맵을 만든다.
--------------------------------------------------
> ### 출력 특성맵
> 출력 특성맵도 높이와 넓이를 가진 3D텐서이다. 출력 텐서의 깊이는 층의 매개변수로 결정되기 때문에 상황에 따라 다르다. 이렇게 되면 깊이 축의 채널은 필터(합성곱 층에서 사용하는 모델 파라미터)를 의미하게 된다. 필터는 입력 데이터의 어떤 특성을 인코딩하는데, 예를 들어 고수준으로 보면 하나의 필터가 '입력에 얼굴이 있는지'를 인코딩할 수 있다. 
> MNIST 예제에서 살펴보면 ``` model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28,28,1))) ``` 에서 첫번째 합성곱 층이 (28, 28, 1) 크기의 특성맵을 입력으로 받아 (26, 26, 32)의 크기의 특성 맵을 출력한다. 즉 입력에 대해 32개의 필터를 적용한다는 것이다(필터 하나의 크기는 patch_height, patch_width, input_depth 이다). 32개의 출력 채널 각각은 26 * 26 의 값을 가진다. 이 값은 입력에 대한 필터의 응답 맵이라고 한다. 그래서 특성맵이란 말이 의미하는 것은 깊이 축에 있는 각 차원은 하나의 특성이고, 2D텐서 output[:, : , n]은 입력에 대한 필터 응답을 나타내는 2D공간상의 맵이다. 
> #### 그래서 합성곱은 핵심적인 2개의 파라미터로 정의된다.
* **입력으로부터 뽑아낼 패치의 크기**
> 전형적으로 3 * 3 또는 5 * 5를 사용한다. 우리의 예시에서는 3 * 3을 사용했다.
* **특성 맵의 출력 깊이**
> 합성곱으로 계산할 필터의 수이다. 우리의 예시에서는 깊이 32로 시작해서 깊이 64로 끝났다.
> #### 케라스의 Conv2D 층에서 이 파라미터는 Conv2D(output_depth, (window_height, window_width))처럼 첫번째와 두번째 매개변수로 전달된다.
-----------------------------------------------------
> ### 합성곱 작동 방식
> 3D입력 특성 맵 위를 3 * 3 또는 5 * 5크기의 윈도우가 슬라이딩하면서 모든 위치에서 3D 특성 패치를 추출하는 방식으로 합성곱이 작동한다. 이런 3D패치는 (output_depth,)크기의 1D벡터로 변환된다(합성곱 커널이라고 불리는 하나의 학습된 가중치 행렬과 텐서곱셈을 통하여 변환된다). 변환된 모든 벡터는 (height, width, output_depth) 크기의 3D 특성 맵으로 재구성 된다. 출력 특성맵의 공간상 위치는 입력 특성 맵의 같은 위치에 대응된다. 
> #### 출력 높이와 너비는 입력의 높이, 너비와 다를 수 있는데 두가지 이유가 있다.
* **경계문제, 입력특성맵에 패딩을 추가하여 대응할 수 있다.**
* **스트라이드(stride)의 사용 여부에 따라 다르다.**
---------------------------------------------------
> ### 경계 문제와 패딩 이해하기
> 5 * 5 크기의 특성맵을 생각해보자. 3 * 3 크기인 윈도우의 중앙을 맞출 수 있는 타일은 3 * 3 격자를 형성하는 9개 뿐이다. 따라서 출력 특성맵은 3 * 3의 크기가 된다. 크기가 조금 줄어서 정확히 2개의 타일들이 높이와 너비를 따라 줄어들었다. 입력과 동일한 높이와 너비를 가진 출력 특성맵을 얻고 싶다면 패딩을 사용할 수 이따. 패딩은 입력 특성 맵의 가장자리에 적절한 개수의 행과 열을 추가한다. 그래서 모든 입력 타일에 합성곱 윈도우의 중앙을 위치시킬수있다!! Conv2D층에서 패딩을 padding 매개변수로 설정할 수 있다. 2개의 값이 가능한데, 'valid'는 패딩을 사용하지 않는 다는 뜻이고, 'same'은 "입력과 동일한 높이와 너비를 가진 출력을 만들기 위해 패딩한다"라는 뜻이다. 이 매개변수의 기본값은 'valid'이다.
> ### 합성곱 스트라이드 이해하기
> 출력 크기에 영향을 미치는 다른 요소는 스트라이드이다. 지금까지 합성곱에 대한 설명은 합성곱 윈도우의 중앙 타일이 연속적으로 지나간다고 가정한 것이다. 두 번의 연속적인 윈도의 사이의 거리가 스트라이드라고 불리는 합성곱의 파라미터이다. 스트라이드의 기본값은 1이다. 스트라이드가 1보다 큰 스트라이드 합성곱도 가능하다. 스트라이드 2를 사용했다는 것은 특성 앱의 너비와 높이가 2의 배수로 다운 샘플링 되었다는 뜻이다. 스트라이드 합성곱은 실전에서 드물게 사용되지만, 어떤 모델에서는 유용하게 사용될 수 있다고 한다!!!
-------------------------------------------------------
> ### 최대 풀링 연산
> 앞선 컨브넷 예제에서 특성 맵의 크기가 MaxPooling2D층마다 절반으로 줄어들었다. 실제로 ```.summaty()```함수를 사용해서 해봤지만 이 연산으로 절반으로 줄어든 것을 확인 할 수 있었다. 스트라이드 합성곱과 비슷하게 강제적으로 특성 맵을 다운 샘플링 하는 것이 최대 풀링의 역할이다.
> 최대 풀링은 입력 특성 맵에서 윈도우에 맞는 패치를 추출하고 각 채널별로 최댓값을 출력한다.
> #### 합성곱과의 차이점?
> 가장 큰 차이점은 최대 풀링은 보통 2 * 2 윈도우와 스트라이드 2를 사용하여 특성 맵을 절반 크기로 다운 샘플링하지만 합성곱은 전형적으로 3 * 3윈도우와 스트라이드 1을 사용한다. 근데 왜 이런식으로 특성 맵을 다운샘플링 하는것일까?? 왜 최대 풀링층 빼고 큰 특성 맵을 계속 유지하지 않을까?? 합성곱으로만 이루어진 모델의 문제는 2가지가 있다.
* **특성의 공간적 계층 구조를 학습하는데 도움이 되지 않는다.**
> 컨브넷에 의해 학습된 고수준 패턴은 초기 입력에 관한 정보가 아주 적어 숫자 분류를 학습하기에 충분하지 않을 것이다. 마지막 합성곱 층의 특성이 전체 입력에 대한 정보를 가지고 있어야 한다.
* **최종 특성맵이 엄청난 가중치를 가지게 될 것이고, 그러면 심각한 과대적합이 발생할 것이다.**
> 간단히 말해서 다운샘플링을 하는 이유는 처리할 특성맵의 가중치 개수를 줄이기 위해서 이다. 또 연속적인 합성곱 층이 점점 커진 윈도우를 통해 바라보도록 만들어 필터의 공간적인 계층 구조를 구성하는거다.
> ### 다른방법??
> 합성곱 층에서 스트라이드를 사용할 수도 있고, 평균 플링 방법을 사용할 수 있다. 하지만 최대 풀링이 다른 방법들보다 더 잘 작동하는 편이다. 그 이유는 특성이 특성맵의 각 타일에서 어떤 패턴이나 개념의 존재 여부를 인코딩하는 경향이 있기 때문이다. 따라서 특성의 평균값보다 최댓값을 사용하는 것이 더 유용한 것이다.
---------------------------------------------
> 다음 예제는 CPU만 사용하면 실행시간이 다소 오래걸릴수있다고 해서...주피터 노트북이 아닌 코랩으로 해볼 예정이다!!
