# 사전 훈련된 컨브넷 사용하기
--------------------------------
> 적은 이미지 데이터셋에 딥러닝을 적용하는 일반적이고 매우 효과적인 방법은 사전 훈련된 네트워크를 사용하는 것이다. **사전 훈련된 네트워크**는 일반적으로
대규모 이미지 분류 문제를 위해 대량의 데이터셋에서 미리 훈련되어 저장된 네트워크이다. 원본 데이터셋이 충분히 크로 일반적이라면 사전 훈련된 네트워크에 의해 학습된 특성의 계층 구조는 실제 세상에 대한 일반적인 모델로 효율적인 역할을 할 수 있다.
새로운 문제가 원래 작업과 완전히 다른 클래스에 대한 것이라도 이런 특성은 많은 컴퓨터 비전 문제에 유용하다.
------------------------------
> 캐런 시몬연과 앤드류 지서먼이 2014년에 개발한 VGG16구조를 사용할 것인데, 두가지 방법이 있다. **특성 추출**과 **미세 조정**방법이 있다.
> ### 특성 추출
> 특성 추출은 사전에 학습된 네트워크의 표현을 사용하여 새로운 샘플에서 흥미로운 특성을 뽑아내는 것이다. 이런 특성을 사용하여 새로운 분류기를 처음부터 훈련한다.
컨브넷의 경우 특성 추출은 사전에 훈련된 네트워크의 합성곱 기반 층을 선택하여 새로운 데이터를 통과시키고, 그 출력으로 새로운 분류기를 훈련하는 것이다.
> ### 미세 조정
> 특성 추출에 사용했던 동결 모델의 상위 층 몇개를 동결에서 해제하고 모델에 새로 추가한 층(여기서는 완전 분류기)과 함께 훈련하는 것이다. 주어진 문제에 조금더 밀접하게 재사용 모델의 표현을 일부 조정하기 때문에 미세 조정이라고 부른다.
> #### 네트워크를 미세 조정하는 단계
* 사전에 훈련된 기반 네트워크 위에 새로운 네트워크를 추가한다.
* 기반 네트워크를 동결한다.
* 새로 추가한 네트워크를 훈련한다.
* 기반 네트워크에서 일부 층의 동결을 해제한다.
* 동결을 해제한 층과 새로 추가한 층을 함께 훈련한다.
> #### 전체 합성곱 기반 층을 미세 조정하지 않는 이유
* 합성곱 기반 층에 있는 하위 층들은 좀 더 일반적이고 재사용 가능한 특성들을 인코딩한다. 반면에 상위층은 좀 더 특화된 특성을 인코딩한다. 새로운 문제에 재활용하도록 수정이 필요한 것은 구체적인 특성이므로 이들을 미세 조정하는 것이 유리하기 때문에 일부 상위층만 하는 것이다.
* 훈련해야 할 파라미터가 많을 수록 과대적합의 위험이 커진다. 합성곱 기반 층은 1,500만개의 파라미터를 가지고 있기에 작은 데이터셋으로 전부 훈련하려고 하면 위험하다.


--------------------------------------
# 정리
* 컨브넷은 컴퓨터 비전 작업에 가장 뛰어난 머신러닝모델이다. 아주 작은 데이터셋에서도 처음부터 훈련해서 괜찮은 성능을 낼 수 있다.
* 작은 데이터셋에서는 과대적합이 큰 문제이다. 데이터 증식은 이미지 데이터를 다룰 때 과대적합을 막을 수 있는 강력한 방법입니다.
* 특성 추출 방식으로 새로운 데이터셋에 기존 컨브넷을 쉽게 재사용할 수 있다. 작은 이미지 데이터셋으로 작업할 때 효과적이다.
* 특성 추출을 보완한 방법은 미세 조정 사용이다. 미세 조정은 기존 모델에서 사전에 학습한 표현의 일부를 새로운 문제에 적응 시키는 것이다. 이 기법은 조금 더 성능을 끌어올린다.
