# 사전 훈련된 단어 임베딩 사용
------------------
사전 훈련된 단어 임베딩을 사용하는 이유는 이미지 분류 문제에서 사전 훈련된 컨브넷을 사용하는 이유와 거의 동일하다. 충분한 데이터가 없어서 자신만의 좋은특성을 학습하지 못하지만 꽤 일반적인 특성이 필요할 때이다.
#### 단어 임베딩은 일반적으로 (문장이나 문서에 같이 등장하는 단어를 관찰하는) 단어 출현 통계를 사용하여 계산된다. 여기에는 여러가지 기법이 있다.
* Word2vec 알고리즘
> 2013년 구글의 토마스 미코로프가 개발했으며, 가장 유명하고 성공적인 단어 임베딩 방법이다. Word2vec의 차원은 성별처럼 구체적인 의미가 있는 속성을 잡아낸다.
* GloVe 기법
> 2014년 스탠포드 대학에서 개발한 임베딩 기법으로 단어의 동시 출현 통계를 기록한 행렬을 분해하는 기법을 사용한다. 이 개발자들은 위키피디아 데이터와 커먼 그롤 데이터에서 가져온 수백만개의 영어 토큰에 대해서 임베딩을 미리 계산해 놓았다.
