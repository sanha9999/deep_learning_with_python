{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 루프에 대한 개념 이해\n",
    "#### RNN 정방향 계산\n",
    "> 이 RNN은 크기가 (timesteps, input_features)인 2D 텐서로 인코딩된 벡터의 시퀀스를 입력 받는다. 이 시퀀스는 타임스템을 따라 반복된다. 각 타임스텝 t에서 현재상태와 ((input_features, 크기의) 입력을 연결하여 출력을 계산한다. 그다음 이 출력을 다음스텝의 상태로 설정한다. 첫 번째 타임스텝에서는 이전 출력이 정의되지 않으므로 현재 상태가 없다. 이때는 네트워크의 **초기 상태**인 0 벡터로 상태를 초기화한다.\n",
    "\n",
    "### 의사코드로 표현한 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_t = 0 # 타임스텝 t의 상태\n",
    "for input_t in input_sequence: # 시퀀스의 원소 반복\n",
    "    output_t = f(input_t, state_t)\n",
    "    state_t = output_t # 출력은 다음 반복을 위한 상태가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 여기서 f 함수는 입력과 상태를 출력으로 변환한다. 이를 2개의 행렬 W와 U 그리고 편향 벡터를 사용하는 변환으로 바꿀 수 있다.\n",
    "\n",
    "### 좀 더 자세한 의사코드로 표현한 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_t = 0\n",
    "for input_t in input_sequence:\n",
    "    output_t = activation(dot(W, input_t) + dot(U, state_t) + b)\n",
    "    state_t = output_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 넘파이로 구현한 간단한 RNN의 정방형 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "timesteps = 100 # 입력 시퀀스애 있는 타임스텝의 수\n",
    "input_features = 32 # 입력 특성의 차원\n",
    "output_features = 64 # 출력 특성의 차원\n",
    "\n",
    "inputs = np.random.random((timesteps, input_features)) # 입력 데이터 : 예제를 위해 생성한 난수\n",
    "\n",
    "state_t = np.zeros((output_features,)) # 모두 0인 초기상태의 벡터\n",
    "\n",
    "# 랜덤한 가중치 행렬을 만든다.\n",
    "W = np.random.random((output_features, input_features))\n",
    "U = np.random.random((output_features, output_features))\n",
    "b = np.random.random((output_features))\n",
    "\n",
    "successive_outputs = []\n",
    "for input_t in inputs:\n",
    "    output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)\n",
    "    # 입력상태와 현재 상태를 연결하여 현재 출력을 얻는다.\n",
    "    successive_outputs.append(output_t)\n",
    "    # 이 출력을 리스트에 저장한다.\n",
    "    state_t = output_t\n",
    "    # 다음 타임 스텝을 위해 네트워크의 상태를 업데이트 한다.\n",
    "    # 기본 RNN의 상태를 은닉 상태라고도 부른다. 은닉 상태는 이전 타임스텝의 출력이다.\n",
    "    \n",
    "final_ouput_sequence = np.stack(successive_outputs, axis=0)\n",
    "# 최종 출력은 크기가 (timesteps, ouput_features)인 2D텐서이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 요약하면 RNN은 반복할 때 이전에 계산한 정보를 재사용하는 for 루프 비슷한 것이다.\n",
    "#### 이 예에서 최종출력은 (timesteps, output_features) 크기인 2D텐서인데, 각 타임스텝은 시간 t에서의 출력을 나타낸다. 출력 텐서의 각 타임스텝 t에는 입력 시퀀스에 있는 타임스텝에서 t까지 전체 과거에 대한 정보를 담고 있다. 이런 이유 때문에 많은 경우 전체 출력 시퀀스가 필요하지 않다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
